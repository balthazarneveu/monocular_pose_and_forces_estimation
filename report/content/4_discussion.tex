\section{Discussion on the Paper}
\label{sec:discussion}

Our review and partial reimplementation of the work by~\citet{li2019estimating} have led us to several observations about 
the original study. We first discuss the overall pipeline (code, vision, evaluation) and then focus on the optimizer. 
\subsection{Overall pipeline}
\begin{itemize}
    \item \textbf{Method and Code Complexity:} The complexity of the approach, both in terms of the underlying methodology and the associated 
    codebase, poses significant barriers to replication and extension. Although it is a research paper, the complexity of the proposed method 
    being quite high, it would truly benefit from industrial development good practices.

    \item \textbf{Simplification of the Vision Pipeline:} The original study uses individual neural network models for each joint in contact recognition
    potentially leading to redundant feature extraction. A more streamlined and modern approach could employ a unified neural network (backbone) to handle 
    these tasks more efficiently. The same remark can be made on the object endpoint detection.

    \item \textbf{Hybrid 2D and 3D estimations pipelines:} Since 3D (HMR) and 2D (OpenPose) poses are estimated independently, there's no
    guarantee of consistency between the two. This may lead to extra jitter for the optimizer which may face two infeasible objectives 
    (meaning that the 3D poses do not reproject well into the 2d poses).
    Using MediaPipe in our re-implementation, one would have naturally expected to have more consistency between 2D and 3D poses. Unfortunately, MediaPipe
    does not grant fixed limb lengths: this may ensure that 3D joints reproject correctly onto 2D points
    but at the cost of having a non rigid body.
    
    \item \textbf{Confidence in Force and Torque Estimations:} Assessing the accuracy of reconstructed forces and torques is problematic due 
    to the limited benchmarks available for validation. The authors deserve credits for providing quantitative results (based on the Parkour dataset ~\cite{maldonado} ).
    Getting ground truth data for these quantities is very challenging. Although realistic simulations do not seem possible, we still believe that an extra
    effort could have been made to provide quantivative results on simulated trajectories with additive noise on the observed data.

\end{itemize}

\subsection{Optimizer}
\begin{itemize}
    \item \textbf{Challenging Loss Coefficient Tuning:} Fine-tuning the loss coefficients in the optimization problem presents a significant 
    challenge. The balance between data fidelity and regularization, requires careful calibration, which may 
    limit the method's generalizability to diverse datasets. As there are no clear guidelines on how to tune these coefficients, one can
    assume that the authors fine tuned them to get correct accuracy on the Parkour dataset used for the quantitative evaluation.

    \item \textbf{Consistency in Object Weight and Body Dimension Priors:} In their method, weights and weight matrices are predefined. 
    But the movement heavily depends on the weight and dimensions of the manipulated object and the human body, which can vary significantly 
    across different videos. 

    \item \textbf{Relevance of Full Body Dynamics:} Given the necessary approximations in velocity and acceleration, and the inability to 
    strictly enforce full-body dynamics, the added value of attempting to reconstruct these dynamics as opposed to focusing 
    solely on kinematics can be questionned. A comparative analysis with kinematics-focused methods could be insightful.

    \item \textbf{Lack of Data Nondimensionalization in Optimization:} The absence of Nondimensionalization or standardization in data processing could 
    affect the model's ability to generalize.
    This issue becomes particularly evident in scenarios where similar movements are performed at 
    different speeds, potentially leading to varied results.
    For instance, one would naturally divide the 2D reprojection errors by the image diagonal size (in pixels), the 3D reprojection errors by the length of the arm,
    the dynamics constraint (torque error) by the static torque of the arm at rest etc... 
    The constants used to weight the cost terms would naturally become more consistent and easier to tune.

    \item \textbf{Torque Regularization:} As discussed in~\cref{subsec:dynamic_results}, the use 
    of \(l_{\text{torque}} = \|\tau_m\|^2\) as a regularization term can lead to suboptimal 
    behavior, particularly in situations where the motion requires significant torques. 
    The simplest correction would be to penalize deviations from the torque obtained in a static configuration deduced from the current state \(l_{\text{torque}} = \|\tau_m - \tau_m^{\textrm{STATIC}} \|^2\).
    Another more appropriate regularization might be on the derivative of the torque, \(\dot{\tau}_m\), which 
    would allow the model to accommodate necessary high torques while still smoothing the energy used in the movement.

\end{itemize}

Additional discussion elements are provided in~\cref{app:additional_discussion}.